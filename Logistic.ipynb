{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "# Load embeddings and labels\n",
    "embeddings_1 = np.load('embeddings_1.npy')\n",
    "embeddings_2 = np.load('embeddings_2.npy')\n",
    "embeddings = np.vstack([embeddings_1, embeddings_2],dtype='float32')  # Combine both embedding files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load labels and convert them to multi-hot encoding\n",
    "with open('icd_codes_1.txt') as f1, open('icd_codes_2.txt') as f2:\n",
    "    labels_1 = [line.strip().split(';') for line in f1]\n",
    "    labels_2 = [line.strip().split(';') for line in f2]\n",
    "    labels = labels_1 + labels_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping for ICD10 codes to multi-hot encoding\n",
    "unique_codes = sorted(set(code for sublist in labels for code in sublist))\n",
    "code_to_index = {code: idx for idx, code in enumerate(unique_codes)}\n",
    "num_classes = len(unique_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to multi-hot vectors\n",
    "y = np.zeros((len(labels), num_classes), dtype=int)\n",
    "for i, label_list in enumerate(labels):\n",
    "    for code in label_list:\n",
    "        y[i, code_to_index[code]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(embeddings, y, test_size=0.15, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize logistic regression model for multi-label classification\n",
    "log_reg = LogisticRegression(max_iter=4000,solver='liblinear',class_weight='balanced')\n",
    "# log_reg = SVC(kernel='sigmoid',gamma='auto',decision_function_shape='ovo')\n",
    "multi_target_clf = OneVsRestClassifier(log_reg, n_jobs=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "multi_target_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on validation set\n",
    "y_pred = multi_target_clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using average micro F2 score\n",
    "micro_f2_score = f1_score(y_val, y_pred, average='micro')\n",
    "\n",
    "print(f\"Average Micro F2 Score on Validation Set: {micro_f2_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data for submission\n",
    "test_embeddings = np.load('test_data.npy')\n",
    "test_predictions = multi_target_clf.predict(test_embeddings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Create a submission file in the specified format\n",
    "# Map indices back to ICD10 codes\n",
    "index_to_code = {v: k for k, v in code_to_index.items()}\n",
    "\n",
    "submission_data = []\n",
    "for idx, label_vector in enumerate(test_predictions, start=1):\n",
    "    # Get codes with predictions above the threshold and sort lexicographically\n",
    "    codes = [index_to_code[i] for i, val in enumerate(label_vector) if val == 1]\n",
    "    codes = sorted(codes)  # Sort lexicographically\n",
    "    label_string = ';'.join(codes) if codes else ''  # Stitch with ';' or leave blank if no label\n",
    "    submission_data.append({'id': idx, 'labels': label_string})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame and save as CSV\n",
    "submission_df = pd.DataFrame(submission_data)\n",
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"Submission file 'submission.csv' created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
